---
title: "Stats Review: Linear Models"
format: 
  revealjs:
    chalkboard: 
      buttons: false
---

# Introduction

## The main theme so far:

Everything we do boils down to `population` and `sample` mean

. . .

::: incremental
-   iid sample mean distributed around population mean
-   use for hypothesis tests, confidence intervals
-   very flexible (lots of things are a population mean)
:::

## Next Steps

-   Show how to estimate a **linear conditional mean**
-   Show it inherits same nice properties
-   Get into some technicalities
-   Review applications

# The Linear Model

## The Linear Model {chalkboard-buttons="true"}

$(y_{i},x_{i,1},x_{i,2},...,x_{i,K})$ is random vector for $i$th observation from sample of size $N$

. . .

```{=tex}
\begin{equation*}
  \mathbb{E}\left[y_{i}\big|\{x_{i,k}\}_{k=1}^{K}\right] = \sum_{k=1}^{K}x_{i,k}\beta_{k} 
\end{equation*}
```
. . .

```{=tex}
\begin{equation*}
  \mathbb{E}\left[y_{i}\big|\{x_{i,k}\}_{k=1}^{K}\right] =[x_{i,1}, x_{i,2}, ..., x_{K}]\left[\begin{array}{c}\beta_{1}\\\beta_{2}\\\vdots\\\beta_{K}\end{array}\right] = \mathbf{x}_{i}{\beta}
\end{equation*}
```
## The Law of Large Numbers

```{R}
library(tidyverse)
library(gganimate)
# set the initial data
d <- data.frame(x = rnorm(1))
d$y = d$x + 0.7*rnorm(1)
D <- d %>%
  mutate(n = 1)
for (t in 2:100) {
  # add one more row to the data
  dn <- data.frame(x = rnorm(1))
  dn$y = dn$x + 0.7*rnorm(1)
  d <- rbind(d,dn)
  # now add this dataset to D
  D <- d %>%
    mutate(n = t) %>%
    rbind(D)
}

# D %>%
#   ggplot(aes(x,y,group=n)) + geom_point() + geom_smooth(method="lm",se=FALSE) + transition_states(n)
```
